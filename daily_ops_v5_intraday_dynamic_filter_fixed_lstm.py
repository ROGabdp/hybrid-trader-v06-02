# -*- coding: utf-8 -*-
"""
================================================================================
Daily Operations - V5 Intraday Dynamic Filter + Fixed LSTM
================================================================================
ç›¤ä¸­åŸ·è¡Œè…³æœ¬ - ä½¿ç”¨ V5 æ¨¡å‹ (å°ç¨±çå‹µè¨“ç·´) + å›ºå®š LSTM æ¨¡å‹ + å‹•æ…‹é«”åˆ¶æ¿¾ç¶²

**å‹•æ…‹æ¿¾ç¶²ç‰¹é»**:
- ä½¿ç”¨ MA120 åˆ¤å®šå¸‚å ´é«”åˆ¶ (Bull/Bear Mode)
- ç†Šå¸‚æ¨¡å¼: åƒ¹æ ¼ < MA120 é€£çºŒ 3 å¤©
- ç†Šå¸‚æ™‚å•Ÿç”¨ Donchian æ¿¾ç¶² (Close > 10æ—¥ High)
- ç‰›å¸‚æ™‚ç„¡æ¿¾ç¶²é™åˆ¶

**Fixed LSTM ç‰¹é»**:
- ä¸é€²è¡Œæ¯æ—¥é‡è¨“ï¼Œçµæœå®Œå…¨å¯é‡ç¾
- è®€å– backtest_v5_dca_hybrid_dynamic_filter_fixed_lstm.py ç”¢ç”Ÿçš„ lstm_info.json
- ä½¿ç”¨èˆ‡å›æ¸¬ç›¸åŒçš„ LSTM æ¨¡å‹ (T+20, T+5, T+1)

æµç¨‹:
1. å¾è­‰äº¤æ‰€ API ä¸‹è¼‰ç•¶æ—¥ OHLC è³‡æ–™ (ç›¤ä¸­å³æ™‚)
2. è®€å–å›æ¸¬ç”¢ç”Ÿçš„ lstm_info.json å–å¾— Fixed LSTM è·¯å¾‘
3. ä½¿ç”¨ Fixed LSTM é€²è¡Œç‰¹å¾µå·¥ç¨‹èˆ‡é æ¸¬
4. é¡¯ç¤ºç›®å‰å¸‚å ´é«”åˆ¶ (ç‰›å¸‚/ç†Šå¸‚) å’Œæ¿¾ç¶²ç‹€æ…‹
5. è¼¸å‡ºçµæœåˆ° intraday_runs_v5_dynamic_filter_fixed/{date}_{time}/
6. ä¸å¯«å…¥ twii_data_from_2000_01_01.csv

ä½œè€…ï¼šPhil Liang (Generated by Gemini)
æ—¥æœŸï¼š2025-12-28
================================================================================
"""

import os
import sys
import shutil
import pickle
import subprocess
import json
import glob
from datetime import datetime, timedelta

# è¨­å®š UTF-8 è¼¸å‡º
sys.stdout.reconfigure(encoding='utf-8')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import numpy as np
import pandas as pd
import yfinance as yf
# [v6.0] LSTM å·²ç§»é™¤ - TensorFlow ä¸å†éœ€è¦

# =============================================================================
# å¼•ç”¨ä¸»ç³»çµ±
# =============================================================================
import ptrl_hybrid_system as core_system

# =============================================================================
# è¨­å®šè·¯å¾‘
# =============================================================================
PROJECT_PATH = os.path.dirname(os.path.abspath(__file__))
INTRADAY_RUNS_PATH = os.path.join(PROJECT_PATH, 'intraday_runs_v5_dynamic_filter_fixed')  # V5 Dynamic Filter å°ˆå±¬è³‡æ–™å¤¾
CSV_FILE = os.path.join(PROJECT_PATH, 'twii_data_from_2000_01_01.csv')

# RL æ¨¡å‹è·¯å¾‘ (V5)
STRATEGY_V5_PATH = os.path.join(PROJECT_PATH, 'models_hybrid_v5')

# å›æ¸¬çµæœè·¯å¾‘ (ç”¨æ–¼è®€å–æŒå€‰ç‹€æ…‹å’Œ LSTM è³‡è¨Š)
BACKTEST_RESULTS_PATH = os.path.join(PROJECT_PATH, 'results_backtest_v5_dca_hybrid_dynamic_filter_fixed_lstm')


# =============================================================================
# è¼”åŠ©å‡½å¼: äº’å‹•å¼ CSV é¸å–®
# =============================================================================
def interactive_select_csv(csv_files: list, default_index: int = -1) -> str:
    """
    ä½¿ç”¨æ–¹å‘éµé¸æ“‡ CSV æª”æ¡ˆ
    
    Args:
        csv_files: CSV æª”æ¡ˆè·¯å¾‘åˆ—è¡¨
        default_index: é è¨­é¸æ“‡çš„ç´¢å¼• (-1 è¡¨ç¤ºæœ€å¾Œä¸€å€‹)
    
    Returns:
        é¸æ“‡çš„æª”æ¡ˆè·¯å¾‘
    """
    import msvcrt
    
    sorted_files = sorted(csv_files)
    current_index = default_index if default_index >= 0 else len(sorted_files) - 1
    
    def render_menu():
        print("\nğŸ“‚ è«‹é¸æ“‡å›æ¸¬ CSV (â†‘â†“ é¸æ“‡, Enter ç¢ºèª):")
        print("-" * 50)
        for i, f in enumerate(sorted_files):
            basename = os.path.basename(f)
            if i == current_index:
                print(f"  â–¶ {basename} â—€")
            else:
                print(f"    {basename}")
        print("-" * 50)
    
    # æ¸…é™¤ä¸¦é¡¯ç¤ºé¸å–®
    render_menu()
    
    while True:
        if msvcrt.kbhit():
            key = msvcrt.getch()
            
            # æ–¹å‘éµåœ¨ Windows æœƒå…ˆè¿”å› 0xe0 æˆ– 0x00
            if key in (b'\xe0', b'\x00'):
                arrow = msvcrt.getch()
                if arrow == b'H':  # ä¸Š
                    current_index = max(0, current_index - 1)
                elif arrow == b'P':  # ä¸‹
                    current_index = min(len(sorted_files) - 1, current_index + 1)
                
                # æ¸…é™¤è¢å¹•ä¸¦é‡ç¹ª
                print("\033[F" * (len(sorted_files) + 4), end='')  # ç§»å‹•æ¸¸æ¨™ä¸Šç§»
                render_menu()
            
            elif key == b'\r':  # Enter
                print(f"\nâœ… å·²é¸æ“‡: {os.path.basename(sorted_files[current_index])}")
                return sorted_files[current_index]
            
            elif key == b'\x1b':  # ESC
                print("\nâ¹ï¸ å–æ¶ˆé¸æ“‡ï¼Œä½¿ç”¨é è¨­ (æœ€æ–°)")
                return sorted_files[-1]


# =============================================================================
# è¼”åŠ©å‡½å¼: è®€å–å›æ¸¬çµæœ
# =============================================================================
def load_latest_backtest_status(backtest_start: str = None, interactive: bool = False) -> dict:
    """
    è®€å–å›æ¸¬ daily_action_strat1 CSV (Strategy 1: Leverage Mode)ï¼Œå–å¾—æŒå€‰ç‹€æ…‹èˆ‡æ§“æ¡¿è³‡è¨Š
    
    Args:
        backtest_start: å¯é¸ï¼ŒæŒ‡å®šå›æ¸¬èµ·å§‹æ—¥æœŸ (æ ¼å¼: YYYYMMDD æˆ– YYYY-MM-DD)
        interactive: è‹¥ç‚º Trueï¼Œå‰‡é¡¯ç¤ºäº’å‹•å¼é¸å–®è®“ç”¨æˆ¶é¸æ“‡
    """
    import glob
    
    result = {
        'found': False,
        'csv_file': None,
        'last_date': None,
        'ai_position_count': 0,
        'dca_position_count': 0,
        'total_position_count': 0,
        'leveraged_mode': False,
        'current_leverage': 1.0,
        'positions_2x': 0,
        'peak_price': 0.0,
        'last_action': 'N/A',
        'last_note': 'N/A'
    }
    
    # å°‹æ‰¾ daily_action CSV (Strat 1)
    pattern = os.path.join(BACKTEST_RESULTS_PATH, 'daily_action_strat1_*.csv')
    csv_files = glob.glob(pattern)
    
    if not csv_files:
        print(f"[Backtest] æ‰¾ä¸åˆ°å›æ¸¬çµæœ: {pattern}")
        return result
    
    sorted_files = sorted(csv_files)
    
    # é¸æ“‡æª”æ¡ˆ
    if interactive and len(sorted_files) > 1:
        # äº’å‹•å¼é¸æ“‡
        target_csv = interactive_select_csv(csv_files)
    elif backtest_start:
        # å‘½ä»¤åˆ—æŒ‡å®š
        start_normalized = backtest_start.replace('-', '')
        matched = [f for f in csv_files if f'_{start_normalized}_' in f]
        if matched:
            target_csv = matched[0]
            print(f"[Backtest] ä½¿ç”¨æŒ‡å®šèµ·å§‹æ—¥: {backtest_start}")
        else:
            print(f"[Backtest] âš ï¸ æ‰¾ä¸åˆ°èµ·å§‹æ—¥ {backtest_start}ï¼Œä½¿ç”¨æœ€æ–°æª”æ¡ˆ")
            target_csv = sorted_files[-1]
    else:
        # é è¨­ä½¿ç”¨æœ€æ–°
        target_csv = sorted_files[-1]
        if len(sorted_files) > 1:
            print(f"[Backtest] æ‰¾åˆ° {len(sorted_files)} å€‹å›æ¸¬çµæœï¼Œä½¿ç”¨æœ€æ–°:")
        
    print(f"[Backtest] è®€å–: {os.path.basename(target_csv)}")
    
    try:
        df = pd.read_csv(target_csv)
        if len(df) == 0:
            return result
        
        last_row = df.iloc[-1]
        
        # è¨ˆç®—ç›®å‰çš„ Peak Price (ä¾ç…§ Strategy 1 é‚è¼¯)
        # é‚è¼¯: éæ§“æ¡¿æ¨¡å¼æ™‚ï¼Œæ›´æ–°æœ€é«˜åƒ¹ï¼›æ§“æ¡¿æ¨¡å¼æ™‚ï¼Œæœ€é«˜åƒ¹é–å®š (ä½œç‚ºå‡ºå ´åŸºæº–)
        current_peak_price = 0
        for _, row in df.iterrows():
            if 'leveraged_mode' in row:
                is_leveraged = bool(row['leveraged_mode'])
                price = float(row['price'])
                if not is_leveraged:
                    if price > current_peak_price:
                        current_peak_price = price
            else:
                current_peak_price = max(current_peak_price, float(row['price']))

        # Update Result
        result.update({
            'found': True,
            'csv_file': os.path.basename(target_csv),
            'last_date': last_row.get('date', 'N/A'),
            'ai_position_count': int(last_row.get('ai_position_count', 0)),
            'dca_position_count': int(last_row.get('dca_position_count', 0)),
            'total_position_count': int(last_row.get('total_position_count', 0)),
            'leveraged_mode': bool(last_row.get('leveraged_mode', False)),
            'current_leverage': float(last_row.get('current_leverage', 1.0)),
            'positions_2x': int(last_row.get('positions_2x', 0)),
            'peak_price': current_peak_price,
            'last_action': last_row.get('ai_action', 'N/A'),
            'last_note': last_row.get('note', 'N/A'),
            'open_positions': []
        })
        
        # å˜—è©¦è®€å– open_positions CSV (Strat 1)
        pos_csv = target_csv.replace('daily_action_strat1_', 'open_positions_strat1_')
        if os.path.exists(pos_csv):
            pos_df = pd.read_csv(pos_csv)
            result['open_positions'] = pos_df.to_dict('records')
            print(f"  æœªå¹³å€‰æŒå€‰: {len(result['open_positions'])} ç­†")
        else:
            print(f"  âš ï¸ æ‰¾ä¸åˆ°æœªå¹³å€‰æŒå€‰æª”æ¡ˆ: {os.path.basename(pos_csv)}")
        
        leverage_status = "ğŸ”¥ ON (2x)" if result['leveraged_mode'] else "OFF (1x)"
        print(f"  æœ€å¾Œæ—¥æœŸ: {result['last_date']}")
        print(f"  æŒå€‰ç‹€æ…‹: ç¸½{result['total_position_count']}å€‰ (DCA{result['dca_position_count']} + AI{result['ai_position_count']})")
        print(f"  æ§“æ¡¿ç‹€æ…‹: {leverage_status} | Peak: {current_peak_price:,.2f}")
        
    except Exception as e:
        print(f"[Error] è®€å–å›æ¸¬ CSV å¤±æ•—: {e}")
    
    return result


# =============================================================================
# Step 0: å»ºç«‹ç›¤ä¸­å°ˆå±¬å·¥ä½œå€
# =============================================================================
def create_intraday_workspace(date_str: str, time_str: str) -> dict:
    folder_name = f"{date_str}_{time_str}"
    intraday_path = os.path.join(INTRADAY_RUNS_PATH, folder_name)
    paths = {
        'root': intraday_path,
        # [v6.0] LSTM å·²ç§»é™¤ - ä¸å†éœ€è¦ lstm_models è³‡æ–™å¤¾
        'cache': os.path.join(intraday_path, 'cache'),
        'reports': os.path.join(intraday_path, 'reports'),
    }
    for key, path in paths.items():
        os.makedirs(path, exist_ok=True)
    print(f"[Workspace] å»ºç«‹ç›¤ä¸­å·¥ä½œå€: {intraday_path}")
    return paths


# =============================================================================
# è¼”åŠ©å‡½å¼: å–å¾—ç›¤ä¸­ OHLC
# =============================================================================
def fetch_intraday_ohlc(ticker: str = "^TWII") -> tuple:
    """
    å¾è­‰äº¤æ‰€ç›¤ä¸­å³æ™‚ API ä¸‹è¼‰ç•¶æ—¥ OHLC è³‡æ–™
    """
    import requests
    
    print(f"\n[Download] æ­£åœ¨å¾è­‰äº¤æ‰€ç›¤ä¸­ API ä¸‹è¼‰å³æ™‚è³‡æ–™...")
    url = "https://mis.twse.com.tw/stock/api/getStockInfo.jsp?ex_ch=tse_t00.tw"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'application/json',
        'Referer': 'https://mis.twse.com.tw/stock/index.jsp'
    }
    
    try:
        r = requests.get(url, headers=headers, timeout=10)
        r.raise_for_status()
        data = r.json()
        msg_array = data.get('msgArray', [])
        
        if not msg_array:
            print("[Error] è­‰äº¤æ‰€ API ç„¡è³‡æ–™ (å¯èƒ½éäº¤æ˜“æ™‚æ®µ)")
            return None
        
        item = msg_array[0]
        raw_date = item.get('d', '')
        if len(raw_date) == 8:
            date_str = f"{raw_date[:4]}-{raw_date[4:6]}-{raw_date[6:8]}"
        else:
            date_str = datetime.now().strftime('%Y-%m-%d')
        
        o = float(item.get('o', 0))
        h = float(item.get('h', 0))
        l = float(item.get('l', 0))
        z = float(item.get('z', 0))
        time_str = item.get('t', 'N/A')
        
        print(f"  ğŸ“… æ—¥æœŸ: {date_str}")
        print(f"  â° æ™‚é–“: {time_str}")
        print(f"  ğŸ“ˆ Open: {o:.2f}")
        print(f"  ğŸ“Š High: {h:.2f}")
        print(f"  ğŸ“‰ Low: {l:.2f}")
        print(f"  ğŸ’° å³æ™‚åƒ¹: {z:.2f}")
        
        return (date_str, o, h, l, z)
        
    except Exception as e:
        print(f"[Error] å–å¾—ç›¤ä¸­è³‡æ–™å¤±æ•—: {e}")
        return None


# =============================================================================
# è¼”åŠ©å‡½å¼: å–å¾—å‰ 5 æ—¥æˆäº¤é‡å¹³å‡
# =============================================================================
def get_avg_volume_from_csv(n_days: int = 5) -> float:
    print(f"\n[Volume] å¾ CSV è¨ˆç®—å‰ {n_days} æ—¥æˆäº¤é‡å¹³å‡...")
    try:
        df = pd.read_csv(CSV_FILE)
        volumes = df['volume'].tail(n_days)
        avg_vol = volumes.mean()
        print(f"  ğŸ“ˆ å¹³å‡æˆäº¤é‡: {avg_vol:.2f} å„„å…ƒ")
        return avg_vol
    except Exception as e:
        print(f"[Error] è®€å– CSV å¤±æ•—: {e}")
        return 3000.0


# =============================================================================
# è¼”åŠ©å‡½å¼: å»ºç«‹æš«å­˜ CSV
# =============================================================================
def create_temp_csv_with_intraday(intraday_data: tuple, avg_volume: float, workspace: dict) -> str:
    print("\n[TempCSV] å»ºç«‹æš«å­˜è¨“ç·´è³‡æ–™...")
    df = pd.read_csv(CSV_FILE)
    date_str, o, h, l, c = intraday_data
    dt = datetime.strptime(date_str, '%Y-%m-%d')
    csv_date = f"{dt.year}/{dt.month}/{dt.day}"
    
    last_date = df['date'].iloc[-1]
    last_dt = datetime.strptime(last_date, '%Y/%m/%d')
    
    if last_dt.date() == dt.date():
        print(f"  [Info] æ›´æ–° {csv_date} çš„è³‡æ–™ç‚ºç›¤ä¸­æ•¸æ“š")
        df.iloc[-1] = [csv_date, o, h, l, c, avg_volume]
    else:
        print(f"  [Info] åŠ å…¥ç›¤ä¸­è³‡æ–™: {csv_date}")
        new_row = pd.DataFrame({
            'date': [csv_date], 'open': [o], 'high': [h], 'low': [l], 'close': [c], 'volume': [avg_volume]
        })
        df = pd.concat([df, new_row], ignore_index=True)
    
    temp_csv_path = os.path.join(workspace['cache'], 'temp_twii_data.csv')
    df.to_csv(temp_csv_path, index=False)
    print(f"  âœ… æš«å­˜ CSV å·²å»ºç«‹: {temp_csv_path}")
    return temp_csv_path


# =============================================================================
# [v6.0] LSTM å·²ç§»é™¤ - ä»¥ä¸‹å‡½å¼å·²åˆªé™¤:
# - load_lstm_info_from_backtest()
# - load_fixed_lstm_for_intraday()
# =============================================================================
# =============================================================================
# Step 2: éš”é›¢å¼ç‰¹å¾µå·¥ç¨‹
# =============================================================================
def feature_engineering(intraday_data: tuple, avg_volume: float) -> pd.DataFrame:
    """
    ç‰¹å¾µå·¥ç¨‹ (ä½¿ç”¨ç›¤ä¸­è³‡æ–™)
    
    [v6.0] LSTM å·²ç§»é™¤
    """
    print("\n" + "=" * 60)
    print("ğŸ”§ Step 2: ç‰¹å¾µå·¥ç¨‹")
    print("=" * 60)
    
    # åˆä½µè³‡æ–™
    print("[Merge] åˆä½µæ­·å²è³‡æ–™èˆ‡ç›¤ä¸­è³‡æ–™...")
    df = pd.read_csv(CSV_FILE)
    df['date'] = pd.to_datetime(df['date'], format='%Y/%m/%d')
    df = df.set_index('date')
    df = df.rename(columns={'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'volume': 'Volume'})
    
    date_str, o, h, l, c = intraday_data
    intraday_dt = pd.Timestamp(date_str)
    
    if intraday_dt in df.index:
        print(f"  [Info] æ›´æ–° {date_str} çš„è³‡æ–™ç‚ºç›¤ä¸­æ•¸æ“š")
        df.loc[intraday_dt] = [o, h, l, c, avg_volume]
    else:
        print(f"  [Info] åŠ å…¥ç›¤ä¸­è³‡æ–™: {date_str}")
        new_row = pd.DataFrame({'Open': [o], 'High': [h], 'Low': [l], 'Close': [c], 'Volume': [avg_volume]}, index=[intraday_dt])
        df = pd.concat([df, new_row])
    
    df = df.sort_index()
    print(f"[Compute] Generating features for ^TWII...")
    return core_system.calculate_features(df, df, ticker="^TWII", use_cache=False)


# =============================================================================
# Step 3: V5 ç­–ç•¥æ¨è«– (å‹•æ…‹æ¿¾ç¶²)
# =============================================================================
def calculate_regime_status(df: pd.DataFrame, lookback: int = 3) -> dict:
    """
    è¨ˆç®—ç›®å‰å¸‚å ´é«”åˆ¶ (Bull/Bear Mode) å’Œæ¿¾ç¶²ç‹€æ…‹
    
    é‚è¼¯:
    - ç†Šå¸‚æ¨¡å¼: åƒ¹æ ¼ < MA120 é€£çºŒ `lookback` å¤©
    - ç†Šå¸‚æ™‚å•Ÿç”¨ Donchian æ¿¾ç¶² (Close > 10æ—¥ High)
    - ç‰›å¸‚æ™‚ç„¡æ¿¾ç¶²é™åˆ¶
    """
    last_rows = df.tail(lookback + 1)
    
    # æª¢æŸ¥ MA120 æ˜¯å¦å­˜åœ¨
    if 'MA120' not in df.columns:
        return {
            'regime': 'BULL',
            'bear_days': 0,
            'ma120': 0,
            'donchian_pass': True,
            'filter_active': False,
            'reason': 'MA120 ä¸å­˜åœ¨ï¼Œé è¨­ç‰›å¸‚'
        }
    
    last_row = df.iloc[-1]
    close_price = float(last_row['Close'])
    ma120 = float(last_row.get('MA120', 0))
    donchian_pass = bool(last_row.get('Signal_Buy_Filter', False))
    
    # è¨ˆç®—é€£çºŒä½æ–¼ MA120 çš„å¤©æ•¸
    bear_days = 0
    for i in range(len(last_rows) - 1, -1, -1):
        row = last_rows.iloc[i]
        if float(row['Close']) < float(row.get('MA120', 0)):
            bear_days += 1
        else:
            break
    
    # åˆ¤å®šé«”åˆ¶
    if bear_days >= lookback:
        regime = 'BEAR'
        filter_active = True
        reason = f'åƒ¹æ ¼ < MA120 é€£çºŒ {bear_days} å¤©ï¼Œå•Ÿç”¨ Donchian æ¿¾ç¶²'
    else:
        regime = 'BULL'
        filter_active = False
        reason = f'ç‰›å¸‚æ¨¡å¼ï¼Œç„¡æ¿¾ç¶²é™åˆ¶'
    
    return {
        'regime': regime,
        'bear_days': bear_days,
        'ma120': ma120,
        'close': close_price,
        'donchian_pass': donchian_pass,
        'filter_active': filter_active,
        'reason': reason
    }


def v5_inference(workspace: dict, df: pd.DataFrame, open_positions: list = None, current_price: float = None,
                 sell_threshold: float = 0.5, buy_consensus_threshold: float = 0.8) -> dict:
    """
    V5 ç­–ç•¥æ¨è«– (å‹•æ…‹æ¿¾ç¶²)
    
    Args:
        workspace: å·¥ä½œå€è³‡è¨Š
        df: ç‰¹å¾µ DataFrame
        open_positions: å¾å›æ¸¬è®€å–çš„ AI æŒå€‰æ¸…å–® (å« buy_price, buy_date)
        current_price: ç›¤ä¸­å³æ™‚åƒ¹ (ç”¨æ–¼è¨ˆç®—å„æŒå€‰å ±é…¬ç‡)
        sell_threshold: è³£å‡ºä¿¡å¿ƒé–€æª» (é è¨­ 0.5)
        buy_consensus_threshold: è²·å…¥å…±è­˜é–€æª» (é è¨­ 0.8)
    """
    print("\n" + "=" * 60)
    print("ğŸ¯ Step 3: V5 ç­–ç•¥æ¨è«– (å‹•æ…‹æ¿¾ç¶²)")
    print(f"   âš™ï¸ Consensus: Sell Threshold > {sell_threshold} | Buy Veto > {buy_consensus_threshold}")
    print("=" * 60)
    
    from stable_baselines3 import PPO
    latest = df.iloc[-1]
    
    # å¦‚æœæ²’å‚³å…¥ current_priceï¼Œå¾ df å–å¾—
    if current_price is None:
        current_price = float(latest['Close'])
    
    # è¨ˆç®—é«”åˆ¶ç‹€æ…‹
    regime_status = calculate_regime_status(df)
    regime = regime_status['regime']
    filter_active = regime_status['filter_active']
    donchian_pass = regime_status['donchian_pass']
    
    # é¡¯ç¤ºé«”åˆ¶ç‹€æ…‹
    regime_icon = "ğŸ‚" if regime == 'BULL' else "ğŸ»"
    print(f"  [é«”åˆ¶] {regime_icon} {regime} Mode (ç†Šå¸‚å¤©æ•¸: {regime_status['bear_days']})")
    print(f"  [MA120] {regime_status.get('ma120', 0):,.2f} | Close: {current_price:,.2f}")
    filter_state = "ON (å•Ÿç”¨ä¸­)" if filter_active else "OFF (æœªå•Ÿç”¨)"
    donchian_state = "âœ…é€šé" if donchian_pass else "âŒæœªé€šé"
    print(f"  [æ¿¾ç¶²] å‹•æ…‹æ¿¾ç¶²: {filter_state} | Donchian: {donchian_state}")
    
    # ä¿ç•™ filter è³‡è¨Š
    signal_buy_filter = donchian_pass
    
    features = np.array([latest.get(col, 0.0) for col in core_system.FEATURE_COLS], dtype=np.float32).reshape(1, -1)
    features = np.nan_to_num(features, nan=0.0, posinf=1.0, neginf=-1.0)
    
    # è¼‰å…¥ V5 æ¨¡å‹
    buy_path = os.path.join(STRATEGY_V5_PATH, 'ppo_buy_twii_final.zip')
    sell_path = os.path.join(STRATEGY_V5_PATH, 'ppo_sell_twii_final.zip')
    
    if not os.path.exists(buy_path):
        return {'error': 'V5 Model not found', 'filter_status': signal_buy_filter, 'regime_status': regime_status}

    try:
        buy_agent = PPO.load(buy_path)
        sell_agent = PPO.load(sell_path)
        
        # ===== Buy Agent =====
        b_act, _ = buy_agent.predict(features, deterministic=True)
        b_obs = buy_agent.policy.obs_to_tensor(features)[0]
        b_prob = buy_agent.policy.get_distribution(b_obs).distribution.probs.detach().cpu().numpy()[0]
        
        ai_action = 'BUY' if b_act[0] == 1 else 'WAIT'
        buy_prob = float(b_prob[1]) if b_act[0] == 1 else float(b_prob[0])
        
        # å‹•æ…‹æ¿¾ç¶²é‚è¼¯: ç†Šå¸‚æ™‚å•Ÿç”¨æ¿¾ç¶²
        if filter_active:
            # ç†Šå¸‚æ¨¡å¼: å¿…é ˆé€šé Donchian æ‰èƒ½è²·
            if ai_action == 'BUY' and not donchian_pass:
                buy_signal = 'FILTERED'
                filter_note = "ğŸš«è¢«æ¿¾ç¶²æ“‹ä¸‹ (ç†Šå¸‚ + Donchianæœªé€šé)"
            else:
                buy_signal = ai_action
                filter_note = "âœ…é€šé" if donchian_pass else "âŒæœªé€šé"
        else:
            # ç‰›å¸‚æ¨¡å¼: ç„¡æ¿¾ç¶²é™åˆ¶
            buy_signal = ai_action
            filter_note = "ğŸ‚ç‰›å¸‚-ç„¡æ¿¾ç¶²"
        
        print(f"  [V5] AI åˆ¤æ–·: {ai_action} ({buy_prob:.1%})")
        print(f"  [V5] æœ€çµ‚æ±ºç­–: {buy_signal} | {filter_note}")
        
        # ===== Sell Agent (çœŸå¯¦æŒå€‰åˆ†æ) =====
        position_decisions = []
        
        if open_positions and len(open_positions) > 0:
            print(f"  [V5] åˆ†æ {len(open_positions)} ç­† AI æŒå€‰...")
            
            for pos in open_positions:
                buy_price = float(pos.get('buy_price', 0))
                buy_date = pos.get('buy_date', 'N/A')
                
                if buy_price > 0:
                    # è¨ˆç®—çœŸå¯¦å ±é…¬ç‡
                    current_return = current_price / buy_price
                    return_pct = (current_return - 1) * 100
                    
                    # æ§‹å»º Sell Agent çš„è§€å¯Ÿå€¼ (ç‰¹å¾µ + å ±é…¬ç‡)
                    s_feat = np.concatenate([features[0], [current_return]]).reshape(1, -1).astype(np.float32)
                    s_act, _ = sell_agent.predict(s_feat, deterministic=True)
                    
                    # å–å¾—æ©Ÿç‡åˆ†å¸ƒä»¥è¨ˆç®—ä¿¡å¿ƒ
                    s_obs = sell_agent.policy.obs_to_tensor(s_feat)[0]
                    s_prob = sell_agent.policy.get_distribution(s_obs).distribution.probs.detach().cpu().numpy()[0]
                    
                    sell_action = 'SELL' if s_act[0] == 1 else 'HOLD'
                    sell_conf = float(s_prob[1]) if s_act[0] == 1 else float(s_prob[0])
                    
                    # åˆ¤æ–·æ˜¯å¦è§¸ç™¼åœæ (ç¡¬æ€§è¦å‰‡: -8%)
                    sell_action = 'SELL' if s_act[0] == 1 else 'HOLD'
                    sell_conf = float(s_prob[1]) if s_act[0] == 1 else float(s_prob[0])
                    
                    # åˆ¤æ–·æ˜¯å¦è§¸ç™¼åœæ (ç¡¬æ€§è¦å‰‡: -8%)
                    triggered_stop_loss = current_return < 0.92

                    # ğŸ”¥ Agent Consensus Logic
                    is_sell_signal = (s_act[0] == 1 and sell_conf > sell_threshold)
                    is_consensus_hold = False
                    veto_reason = ""
                    
                    if is_sell_signal and not triggered_stop_loss:
                        if buy_prob > buy_consensus_threshold:
                            is_consensus_hold = True
                            veto_reason = f"ğŸš« Consensus Veto (Buy Conf {buy_prob:.1%} > {buy_consensus_threshold})"
                            print(f"    -> Sell Signal Vetoed! {veto_reason}")

                    final_action = 'HOLD'
                    if triggered_stop_loss:
                        final_action = 'SELL'
                    elif is_sell_signal and not is_consensus_hold:
                        final_action = 'SELL'
                    
                    position_decisions.append({
                        'buy_date': buy_date,
                        'buy_price': buy_price,
                        'current_return': current_return,
                        'return_pct': return_pct,
                        'action': sell_action,
                        'confidence': sell_conf,
                        'triggered_stop_loss': triggered_stop_loss,
                        'is_consensus_hold': is_consensus_hold,
                        'veto_reason': veto_reason,
                        'final_action': final_action
                    })
        else:
            print(f"  [V5] ç„¡ AI æŒå€‰ï¼Œè·³é Sell Agent åˆ†æ")
        
        return {
            'filter_status': signal_buy_filter,
            'buy_signal': buy_signal,
            'buy_prob': buy_prob,
            'ai_action': ai_action,
            'position_decisions': position_decisions,
            'regime_status': regime_status  # é«”åˆ¶ç‹€æ…‹
        }
    except Exception as e:
        print(f"  [Error] V5 Inference: {e}")
        return {'error': str(e), 'filter_status': signal_buy_filter, 'regime_status': regime_status}


# =============================================================================
# Step 4: è¼¸å‡ºç›¤ä¸­å ±å‘Š
# =============================================================================
def generate_intraday_report(workspace: dict, df: pd.DataFrame, res: dict, date_str: str, intraday_data: tuple, avg_volume: float, backtest_status: dict = None):
    print("\n" + "=" * 60)
    print("ğŸ“Š Step 4: ç›¤ä¸­æˆ°æƒ…å„€è¡¨æ¿ (V5 Dynamic Filter)")
    print("=" * 60)
    
    last = df.iloc[-1]
    filter_status = res.get('filter_status', False)
    _, o, h, l, c = intraday_data
    
    lines = []
    lines.append("=" * 50)
    lines.append(f"ğŸ“… V5 ç›¤ä¸­å³æ™‚åˆ†æ (å‹•æ…‹æ¿¾ç¶²) - {date_str}")
    lines.append(f"â° æ›´æ–°æ™‚é–“: {datetime.now().strftime('%H:%M:%S')}")
    lines.append("=" * 50)
    lines.append(f"ğŸ“Š Open:  {o:,.2f}")
    lines.append(f"ğŸ“ˆ High:  {h:,.2f}")
    lines.append(f"ğŸ“‰ Low:   {l:,.2f}")
    lines.append(f"ğŸ’° Close: {c:,.2f} (å³æ™‚)")
    lines.append(f"ğŸ“¦ Volume: {avg_volume:.2f} å„„å…ƒ (å‰5æ—¥å¹³å‡ä¼°è¨ˆ)")
    lines.append("-" * 50)
    
    # å‹•æ…‹é«”åˆ¶ç‹€æ…‹ (æ ¸å¿ƒè³‡è¨Š)
    regime_status = res.get('regime_status', {})
    regime = regime_status.get('regime', 'BULL')
    bear_days = regime_status.get('bear_days', 0)
    ma120 = regime_status.get('ma120', 0)
    filter_active = regime_status.get('filter_active', False)
    donchian_pass = regime_status.get('donchian_pass', False)
    
    regime_icon = "ğŸ‚" if regime == 'BULL' else "ğŸ»"
    lines.append(f"ğŸ“Š [å¸‚å ´é«”åˆ¶ç›£æ§] (MA120 å‹•æ…‹æ¿¾ç¶²)")
    lines.append(f"   é«”åˆ¶: {regime_icon} {regime} Mode")
    lines.append(f"   MA120: {ma120:,.2f} | å³æ™‚åƒ¹: {c:,.2f}")
    
    if regime == 'BEAR':
        lines.append(f"   ç†Šå¸‚å¤©æ•¸: {bear_days} å¤© (é€£çºŒä½æ–¼ MA120)")
        donchian_icon = "âœ…" if donchian_pass else "ğŸš«"
        lines.append(f"   æ¿¾ç¶²ç‹€æ…‹: ğŸ”´ å•Ÿç”¨ä¸­ | Donchian: {donchian_icon} {'é€šé' if donchian_pass else 'æœªé€šé'}")
        if not donchian_pass:
            lines.append(f"   âš ï¸ AI è²·å…¥è¨Šè™Ÿå°‡è¢«æ“‹ä¸‹ (éœ€çªç ´ 10æ—¥ High)")
    else:
        lines.append(f"   æ¿¾ç¶²ç‹€æ…‹: ğŸŸ¢ æœªå•Ÿç”¨ (ç‰›å¸‚è‡ªç”±æ¨¡å¼)")
        lines.append(f"   â„¹ï¸ AI å¯è‡ªç”±åˆ¤æ–·è²·è³£ï¼Œç„¡æ¿¾ç¶²é™åˆ¶")
    lines.append("-" * 50)
    
    # æ§“æ¡¿ç‹€æ…‹ (Strategy 1 Only)
    if backtest_status and 'leveraged_mode' in backtest_status:
        lev_mode = backtest_status['leveraged_mode']
        peak_price = backtest_status.get('peak_price', 0)
        
        lev_icon = "ğŸ”¥" if lev_mode else "â„ï¸"
        lev_str = "ON (2å€æ§“æ¡¿)" if lev_mode else "OFF (1å€æ§“æ¡¿)"
        
        lines.append(f"âš¡ [2x æ§“æ¡¿ç›£æ§] (Strategy 1)")
        lines.append(f"   ç‹€æ…‹: {lev_icon} {lev_str}")
        
        if peak_price > 0:
            current_close = float(c)
            dd_pct = (current_close - peak_price) / peak_price
            lines.append(f"   é«˜é»: {peak_price:,.2f} | ç›®å‰è·Œå¹…: {dd_pct*100:.2f}%")
            if not lev_mode:
                trigger_price = peak_price * 0.92  # 8% threshold
                dist_to_trigger = (current_close - trigger_price) / current_close
                lines.append(f"   è§¸ç™¼: {trigger_price:,.2f} (è·é›¢: {dist_to_trigger*100:.2f}%)")
            else:
                lines.append(f"   é€€å‡º: {peak_price:,.2f} (å›åˆ°é«˜é»å³é€€å‡º)")
        lines.append("-" * 50)

    # [v6.0] LSTM å·²ç§»é™¤ - ä¸å†è¼¸å‡º LSTM é æ¸¬

    # V5 é¡¯æ€§ç‰¹å¾µåˆ—è¡¨
    lines.append("ğŸ“ [é—œéµç‰¹å¾µ]")
    lines.append(f"   MA20 å‹•èƒ½: {last.get('Feat_MA20_Slope', 0)*100:+.2f}%  (>0 è½‰å¼·)")
    lines.append(f"   å¸‚å ´é«”åˆ¶: {last.get('Feat_Trend_Gap', 0)*100:+.2f}%  (>0 å¤šé ­çµæ§‹)")
    lines.append(f"   çŸ­ç·šä¹–é›¢: {last.get('Feat_Bias_MA20', 0)*100:+.2f}%")
    lines.append(f"   å­£ç·šè·é›¢: {last.get('Feat_Dist_MA60', 0)*100:+.2f}%")
    lines.append(f"   å¹´ç·šä½ç½®: {last.get('Feat_Dist_MA240', 0)*100:+.2f}%  (>0 é•·å¤š)")
    lines.append(f"   ç›¸å°é‡èƒ½: {last.get('Feat_Vol_Ratio', 0):.2f}x   (>1.0 æ”¾é‡)")
    lines.append("-" * 50)
    
    # V5 RL
    lines.append("ğŸ¤– [æ“ç›¤æ‰‹ V5] (å°ç¨±çå‹µ + å‹•æ…‹æ¿¾ç¶²)")
    if 'error' in res:
        lines.append(f"   âŒ éŒ¯èª¤: {res['error']}")
    else:
        buy_signal = res['buy_signal']
        buy_prob = res['buy_prob']
        buy_icon = "ğŸš€" if buy_signal == 'BUY' else "ğŸ’¤" if buy_signal == 'WAIT' else "ğŸš«"
        
        lines.append(f"   ğŸ›’ è²·å…¥è¨Šè™Ÿ: {buy_icon} {buy_signal} ({buy_prob:.1%})")

    lines.append("-" * 50)
    
    # Advice (å‹•æ…‹æ¿¾ç¶²ç‰ˆ)
    buy_signal = res.get('buy_signal', 'N/A')
    ai_action = res.get('ai_action', 'N/A')
    
    if buy_signal == 'BUY':
        advice = "â­â­ V5 å¼·åŠ›è²·é€² (Strong Buy) â­â­"
    elif buy_signal == 'FILTERED':
        advice = "ğŸš« AI æƒ³è²·ä½†è¢«æ¿¾ç¶²æ“‹ä¸‹ (ç†Šå¸‚é˜²ç·š)"
    elif buy_signal == 'WAIT' or ai_action == 'WAIT':
        advice = "ğŸ’¤ ç©ºæ‰‹è§€æœ› (Wait)"
    else:
        advice = "â“ è¨Šè™Ÿä¸æ˜"
    
    # æ¨™æ³¨é«”åˆ¶ç‹€æ…‹
    regime_note = f"{regime_icon}{regime}" if regime else "BULL"
    advice += f" [{regime_note}]"
        
    lines.append(f"ğŸ’¡ ç›¤ä¸­å»ºè­°: {advice}")
    lines.append("-" * 50)
    
    # å›æ¸¬æŒå€‰ç‹€æ…‹
    if backtest_status and backtest_status.get('found'):
        # è§£æ CSV æª”åä¸­çš„æ—¥æœŸ
        csv_file = backtest_status.get('csv_file', 'N/A')
        # æª”åæ ¼å¼: daily_action_strat2_YYYYMMDD_YYYYMMDD.csv
        import re
        date_match = re.search(r'(\d{8})_(\d{8})\.csv$', csv_file)
        if date_match:
            start_date = f"{date_match.group(1)[:4]}-{date_match.group(1)[4:6]}-{date_match.group(1)[6:8]}"
            end_date = f"{date_match.group(2)[:4]}-{date_match.group(2)[4:6]}-{date_match.group(2)[6:8]}"
            date_range_str = f"{start_date} ~ {end_date}"
        else:
            date_range_str = csv_file
        
        lines.append(f"ğŸ’¼ [å›æ¸¬æŒå€‰ç‹€æ…‹] æª”æ¡ˆ: {csv_file}")
        lines.append(f"   ğŸ“… å›æ¸¬æœŸé–“: {date_range_str}")
        lines.append(f"   ğŸ›ï¸  DCA å€‰ä½: {backtest_status['dca_position_count']} å€‰")
        lines.append(f"   ğŸ¤– AI å€‰ä½: {backtest_status['ai_position_count']} å€‰")
        lines.append(f"   ğŸ“Š ç¸½å€‰æ•¸: {backtest_status['total_position_count']} å€‰")
        lines.append(f"   ğŸ“ æœ€å¾Œæ“ä½œ: {backtest_status['last_note']}")
        
        # é æ¸¬ä»Šæ—¥æ“ä½œ
        lines.append("-" * 50)
        lines.append("ğŸ”® [ä»Šæ—¥é æ¸¬] (åŸºæ–¼ç›¤ä¸­åƒ¹æ ¼æ¨¡æ“¬)")
        
        ai_action = res.get('ai_action', 'WAIT')
        ai_positions = backtest_status['ai_position_count']
        dca_positions = backtest_status['dca_position_count']
        
        # é æ¸¬è²·å…¥ (V5: ç„¡æ¿¾ç¶²é™åˆ¶ï¼Œç´”çœ‹ AI æ±ºç­–)
        predicted_buy = 0
        if ai_action == 'BUY':
            lines.append(f"   ğŸŸ¢ è²·å…¥é æ¸¬: AI+1å€‰ (V5 ç„¡æ¿¾ç¶²é™åˆ¶, AIå»ºè­°BUY)")
            predicted_buy = 1
        else:
            lines.append(f"   âšª è²·å…¥é æ¸¬: ç„¡ (AI:{ai_action})")
        
        # é æ¸¬è³£å‡º (ä½¿ç”¨ position_decisions)
        position_decisions = res.get('position_decisions', [])
        predicted_sell = 0
        current_price = float(intraday_data[4])  # intraday_data = (date, o, h, l, c)
        
        if position_decisions:
            lines.append("-" * 50)
            lines.append("ğŸ“¦ [AIæŒå€‰æ˜ç´° + Sell Agent åˆ¤æ–·]")
            
            for i, pd in enumerate(position_decisions, 1):
                buy_date = pd.get('buy_date', 'N/A')
                buy_price = pd.get('buy_price', 0)
                return_pct = pd.get('return_pct', 0)
                action = pd.get('action', 'HOLD')
                confidence = pd.get('confidence', 0)
                final_action = pd.get('final_action', 'HOLD')
                triggered_stop_loss = pd.get('triggered_stop_loss', False)
                
                # æ±ºå®šé¡¯ç¤ºæ ¼å¼
                # æ±ºå®šé¡¯ç¤ºæ ¼å¼
                if triggered_stop_loss:
                    status_icon = "ğŸ”´ SELL"
                    reason = f"åœæè§¸ç™¼ (AI: {action} {confidence:.1%})"
                elif final_action == 'SELL':
                    status_icon = "ğŸ”´ SELL"
                    reason = f"AIæ±ºå®š ({confidence:.1%})"
                elif pd.get('is_consensus_hold', False):
                    status_icon = "ğŸŸ¢ HOLD"
                    reason = f"AIè³£è¨Šè¢«å¦æ±º ({pd.get('veto_reason')})"
                else:
                    status_icon = "ğŸŸ¢ HOLD"
                    reason = f"AIæ±ºå®š ({confidence:.1%})"
                
                lines.append(f"   #{i} è²·å…¥: {buy_date} @ {buy_price:,.2f}")
                lines.append(f"       å ±é…¬: {return_pct:+.2f}% | {status_icon} {reason}")
                
                if final_action == 'SELL':
                    predicted_sell += 1
        elif ai_positions > 0:
            lines.append(f"   âš ï¸ ç„¡æŒå€‰æ˜ç´°è³‡æ–™")
        else:
            lines.append(f"   âšª è³£å‡ºé æ¸¬: ç„¡ (AI ç„¡æŒå€‰)")
        
        # è¨ˆç®—é ä¼°ç¸½å€‰
        predicted_ai = ai_positions + predicted_buy - predicted_sell
        predicted_total = dca_positions + predicted_ai
        
        lines.append("-" * 50)
        lines.append("ğŸ“Š [é ä¼°æ”¶ç›¤å¾Œå€‰ä½]")
        lines.append(f"   DCA: {dca_positions} å€‰ (ä¸è®Š)")
        change = predicted_buy - predicted_sell
        change_str = f"+{change}" if change > 0 else str(change) if change < 0 else "Â±0"
        lines.append(f"   AI:  {ai_positions} â†’ {predicted_ai} å€‰ ({change_str})")
        lines.append(f"   ç¸½è¨ˆ: {backtest_status['total_position_count']} â†’ {predicted_total} å€‰")
        
    else:
        lines.append("ğŸ’¼ [å›æ¸¬æŒå€‰ç‹€æ…‹] æœªæ‰¾åˆ°å›æ¸¬çµæœ")
        lines.append("   è«‹å…ˆåŸ·è¡Œ: python backtest_v5_dca_hybrid_no_filter_fixed_lstm.py --start 2025-01-02")
    
    lines.append("=" * 50)
    
    report = "\n".join(lines)
    print(report)
    
    # Save
    with open(os.path.join(workspace['reports'], 'intraday_summary.txt'), 'w', encoding='utf-8') as f:
        f.write(report)
    
    json_data = {
        'date': date_str,
        'filter_status': filter_status,
        'market': {'close': c, 'volume_est': avg_volume},
        # [v6.0] LSTM å·²ç§»é™¤ - ä¸å†è¼¸å‡º LSTM é æ¸¬
        'v5': res,
        'advice': advice
    }
    with open(os.path.join(workspace['reports'], 'intraday_summary.json'), 'w', encoding='utf-8') as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)
    
    print(f"\n[Report] å·²å„²å­˜è‡³: {workspace['reports']}")


# =============================================================================
# Main
# =============================================================================
def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='V5 ç›¤ä¸­åˆ†æç³»çµ± (Dynamic Filter + Fixed LSTM)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ä½¿ç”¨ç¯„ä¾‹:
  python daily_ops_v5_intraday_dynamic_filter_fixed_lstm.py                    # ä½¿ç”¨æœ€æ–°å›æ¸¬çµæœ
  python daily_ops_v5_intraday_dynamic_filter_fixed_lstm.py -i                 # äº’å‹•å¼é¸æ“‡å›æ¸¬ CSV
  python daily_ops_v5_intraday_dynamic_filter_fixed_lstm.py --backtest-start 2025-01-02  # æŒ‡å®šå›æ¸¬èµ·å§‹æ—¥
        '''
    )
    parser.add_argument(
        '-i', '--interactive',
        action='store_true',
        help='äº’å‹•å¼é¸æ“‡å›æ¸¬ CSV æª”æ¡ˆ (ä½¿ç”¨æ–¹å‘éµ)'
    )
    parser.add_argument(
        '--backtest-start', 
        type=str, 
        default=None,
        help='å›æ¸¬èµ·å§‹æ—¥æœŸ (YYYY-MM-DD æˆ– YYYYMMDD æ ¼å¼)'
    )
    parser.add_argument('--sell-threshold', type=float, default=0.5, help='Confidence threshold for sell signals')
    parser.add_argument('--buy-consensus-threshold', type=float, default=0.8, help='Buy confidence threshold to veto sell signals')
    args = parser.parse_args()
    
    now = datetime.now()
    date_str = now.strftime('%Y-%m-%d')
    time_str = now.strftime('%H%M%S')
    
    print(f"ğŸš€ V5 ç›¤ä¸­åˆ†æç³»çµ± (Dynamic Filter) - {date_str} {time_str}")
    
    # Step 0
    ws = create_intraday_workspace(date_str, time_str)
    
    # Step 0.4: è®€å–å›æ¸¬æŒå€‰ç‹€æ…‹
    print("\n[Backtest] è®€å–å›æ¸¬æŒå€‰ç‹€æ…‹...")
    backtest_status = load_latest_backtest_status(args.backtest_start, interactive=args.interactive)
    
    # Step 0.5
    intraday_data = fetch_intraday_ohlc("^TWII")
    if not intraday_data: sys.exit(1)
    
    # Step 0.6
    avg_volume = get_avg_volume_from_csv(5)
    
    # [v6.0] LSTM å·²ç§»é™¤ - è·³é Step 1
    
    # Step 2: ç‰¹å¾µå·¥ç¨‹
    df = feature_engineering(intraday_data, avg_volume)
    
    # Step 3: V5 ç­–ç•¥æ¨è«– (å‚³å…¥çœŸå¯¦æŒå€‰è³‡è¨Š)
    open_positions = backtest_status.get('open_positions', []) if backtest_status else []
    current_price = float(intraday_data[4])  # intraday_data = (date, o, h, l, c)
    res = v5_inference(
        ws, df, 
        open_positions=open_positions, 
        current_price=current_price,
        sell_threshold=args.sell_threshold,
        buy_consensus_threshold=args.buy_consensus_threshold
    )
    
    # Step 4
    generate_intraday_report(ws, df, res, intraday_data[0], intraday_data, avg_volume, backtest_status)
    print("Done.")

if __name__ == "__main__":
    main()
